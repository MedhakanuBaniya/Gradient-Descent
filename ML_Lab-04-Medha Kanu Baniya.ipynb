{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9181a101",
   "metadata": {},
   "source": [
    "# Task 1: Problem # 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af3e06",
   "metadata": {},
   "source": [
    "In this laboratory task, you will execute multivariable linear regression through the utilization of the Matrix-Vector \n",
    "Multiplication approach with Gradient Descent. Please follow the solution that I provided for the Midterm exam. \n",
    "Show me that your Python code gives the same result that I have in the solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6fad47",
   "metadata": {},
   "source": [
    "Determine the parametrs for linear regression, compute both theta0,theta1,theta2,theta3,theta4 and cost function for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c751b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436e5ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      " θ values: [ 0.125    0.15625 -0.025    0.15625]\n",
      "Cost function: 0.14647841796875\n",
      "\n",
      "Iteration 2:\n",
      " θ values: [ 0.06921875  0.16550781 -0.134125    0.02019531]\n",
      "Cost function: 0.1196066831010437\n",
      "\n",
      "Iteration 3:\n",
      " θ values: [ 0.13180098  0.25668306 -0.17963629  0.08681743]\n",
      "Cost function: 0.10054495192180492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_ones_column(data):\n",
    "    return np.column_stack([np.ones(data.shape[0]), data])\n",
    "\n",
    "def gradient_descent(x, y, θ, alpha, num_iterations):\n",
    "    for iteration in range(num_iterations):\n",
    "        predictions = np.dot(x, θ)\n",
    "        errors = predictions - y\n",
    "        gradient = np.dot(x.T, errors) / len(y)\n",
    "        \n",
    "        # Update parameters θ using the gradient\n",
    "        θ -= (alpha * gradient)\n",
    "\n",
    "        # Calculate the cost function after each iteration.\n",
    "        updated_predictions = np.dot(x, θ)\n",
    "        updated_errors = updated_predictions - y\n",
    "        cost = np.mean(updated_errors ** 2) / 2\n",
    "        \n",
    "        print(f\"Iteration {iteration + 1}:\")\n",
    "        print(\" θ values:\", θ)\n",
    "        print(\"Cost function:\", cost)\n",
    "        print()\n",
    "\n",
    "# Input data\n",
    "data = np.array([\n",
    "    [0.5, 1.0, 2.0, -0.5],\n",
    "    [1.0, 0.2, 2.0, 1.0],\n",
    "    [1.0, 0.2, 0.5, 0.5],\n",
    "    [-1.0, -0.5, 0.2, 0.0]\n",
    "])\n",
    "\n",
    "# Separate the features x and y\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Adding 1's column to the features for the bias term θ0\n",
    "x = add_ones_column(x)\n",
    "\n",
    "# Initialize parameters θ with zeros\n",
    "θ = np.zeros(x.shape[1])\n",
    "\n",
    "# Set hyperparameters\n",
    "alpha = 0.5\n",
    "num_iterations = 3\n",
    "\n",
    "# Perform Gradient Descent\n",
    "gradient_descent(x, y, θ, alpha, num_iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547af3f8",
   "metadata": {},
   "source": [
    "ii) After 3rd iteration , predict the outputs for given i/p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076b44f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output values: [ 0.14758725 -0.05602828  0.11943419  0.32471112]\n"
     ]
    }
   ],
   "source": [
    "# New data for prediction\n",
    "data1 = np.array([\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [-1, 0.1, 1],\n",
    "    [0.5, 0.3, -1],\n",
    "    [1, 0.5, 0.3]\n",
    "])\n",
    "\n",
    "# Adding 1's column to the features for the bias term θ0\n",
    "x1 = add_ones_column(data1)\n",
    "\n",
    "# Make predictions using the trained θ values\n",
    "predicted_output = np.dot(x1, θ)\n",
    "print(\"Predicted output values:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714014e",
   "metadata": {},
   "source": [
    "# Task 2: Problem # 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1a25a",
   "metadata": {},
   "source": [
    "In this laboratory task, you will execute Polynomial linear regression through the utilization of the Matrix-Vector \n",
    "Multiplication approach with Gradient Descent.\n",
    "\n",
    "Please follow the solution that I provided for the Midterm exam. Show me that your Python code gives the same result that \n",
    "I have in the solution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010af4bc",
   "metadata": {},
   "source": [
    "1. add a new feature x2=x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b667b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data set: x2 = x^2: [[  89 7921   96]\n",
      " [  72 5184   74]\n",
      " [  94 8836   87]\n",
      " [  69 4761   78]]\n"
     ]
    }
   ],
   "source": [
    "# Data set\n",
    "data = np.array([\n",
    "    [89, 96],\n",
    "    [72, 74],\n",
    "    [94, 87],\n",
    "    [69, 78]\n",
    "])\n",
    "\n",
    "# Adding a new feature x2 = x^2\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "new_data = np.column_stack([x, x[:, 0] ** 2,y])\n",
    "print(\"new data set: x2 = x^2:\",new_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffa429",
   "metadata": {},
   "source": [
    "2. Feature normalize each feature so that each feature has zero mean and unit varience, report new features are now in new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1bd2fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset with normalized features:\n",
      " [[ 0.64746735  0.61994303]\n",
      " [-0.72840077 -0.74238862]\n",
      " [ 1.05213445  1.0753809 ]\n",
      " [-0.97120103 -0.95293531]]\n"
     ]
    }
   ],
   "source": [
    "x = new_data[:, :-1]\n",
    "\n",
    "# mean and standard deviation for each feature\n",
    "mean = np.mean(x, axis=0)\n",
    "std = np.std(x, axis=0, ddof=1) \n",
    "\n",
    "# Feature normalize\n",
    "normalized_feature = (x - mean) / std\n",
    "\n",
    "print(\"New dataset with normalized features:\\n\", normalized_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189680f2",
   "metadata": {},
   "source": [
    "3. given initialvalues theta0=theta1=theta2=theta3=0 and learn rate alpha=0.75 , compute N=3 iterations of gradient descentusing feature normalized training data and determine the parametrs for polynomial regression. Compute both theta0,theta1,theta2,theta3 and cost function for each iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36bad326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data set: [[ 0.64746735  0.61994303 96.        ]\n",
      " [-0.72840077 -0.74238862 74.        ]\n",
      " [ 1.05213445  1.0753809  87.        ]\n",
      " [-0.97120103 -0.95293531 78.        ]]\n",
      "X: [[ 1.          1.          1.          1.        ]\n",
      " [ 0.64746735 -0.72840077  1.05213445 -0.97120103]\n",
      " [ 0.61994303 -0.74238862  1.0753809  -0.95293531]]\n",
      "Iteration 1:\n",
      "θ values: [62.8125      4.50697978  4.46380445]\n",
      "Cost function: 231.80549899506798\n",
      "\n",
      "Iteration 2:\n",
      "θ values: [78.515625    3.96865812  3.88231485]\n",
      "Cost function: 25.94832950809302\n",
      "\n",
      "Iteration 3:\n",
      "θ values: [82.44140625  4.06013067  3.93062687]\n",
      "Cost function: 13.098255504347405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data_set = np.column_stack([x,y])\n",
    "\n",
    "# Separate features x and y\n",
    "x = new_data_set[:,:-1]\n",
    "y = new_data_set[:,-1]\n",
    "\n",
    "# Adding 1's column to the features for the bias term θ0\n",
    "X = np.column_stack([np.ones(x.shape[0]), x])\n",
    "print(\"new data set:\",new_data_set)\n",
    "\n",
    "# Initialize parameters θ with zeros\n",
    "θ = np.zeros(X.shape[1])\n",
    "alpha = 0.75\n",
    "N = 3\n",
    "M = 4\n",
    "\n",
    "# Gradient Descent\n",
    "for iteration in range(N):\n",
    "    predictions = np.dot(X, θ)\n",
    "    errors = predictions - y\n",
    "    gradient = np.dot(X.T, errors)\n",
    "    \n",
    "    θ -= (alpha * gradient) / M\n",
    "    print(f\"Iteration {iteration + 1}:\")\n",
    "    print(\"θ values:\", θ)\n",
    "\n",
    "    # cost calculation after each iteration with updated paramers.\n",
    "    updated_predictions = np.dot(X, θ)\n",
    "    updated_errors = updated_predictions - y\n",
    "    cost = np.mean(updated_errors ** 2) / 2\n",
    "\n",
    "    print(\"Cost function:\", cost)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61aef8",
   "metadata": {},
   "source": [
    "# Task 3: Problem # 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d9d66",
   "metadata": {},
   "source": [
    "1. given initialvalues theta0=theta1=theta2=theta3=0 and learn rate alpha=0.5 , compute k=1 iterations of stochastic gradient descent. after each update for each training example show what theta0,theta1,theta2,theta3 as well as their costs for each training example. once you iterate through all the training examples, calculate what the avg cost over all of the individual costs would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37ad302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Example 1:\n",
      "Theta values: [-0.25  -0.125 -0.25  -0.5  ]\n",
      "Cost: 1.12890625\n",
      "\n",
      "Training Example 2:\n",
      "Theta values: [ 0.9625  1.0875 -0.0075  1.925 ]\n",
      "Cost: 23.995302249999995\n",
      "\n",
      "Training Example 3:\n",
      "Theta values: [-0.293   -0.168   -0.2586   1.29725]\n",
      "Cost: 0.13256516902499987\n",
      "\n",
      "Training Example 4:\n",
      "Theta values: [-0.424875  -0.036125  -0.1926625  1.270875 ]\n",
      "Cost: 0.001462584414062506\n",
      "\n",
      "Average Cost over the Iterations: 6.314559063359765\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data = np.array([\n",
    "    [0.5, 1, 2, -0.5],\n",
    "    [1, 0.2, 2, 1],\n",
    "    [1, 0.2, 0.5, 0.5],\n",
    "    [-1, -0.5, 0.2, 0]\n",
    "])\n",
    "\n",
    "# Extract features (x1, x2, x3) and the target value (y)\n",
    "features = data[:, :-1]\n",
    "target = data[:, -1]\n",
    "\n",
    "# Initialize parameters theta with zeros\n",
    "theta = np.array([0, 0, 0, 0])\n",
    "learning_rate = 0.5\n",
    "total_cost = 0\n",
    "\n",
    "# Stochastic Gradient Descent iterations\n",
    "for i in range(len(data)):\n",
    "    feature_i = np.insert(features[i], 0, 1)  # Adding a bias term\n",
    "    target_i = target[i]\n",
    "    \n",
    "    # Calculate the current prediction\n",
    "    prediction = np.dot(theta, feature_i)\n",
    "    error = prediction - target_i\n",
    "    \n",
    "    # Update the theta values\n",
    "    theta = theta - learning_rate * error * feature_i\n",
    "    \n",
    "    # Calculate and accumulate the cost for each iteration\n",
    "    prediction = np.dot(theta, feature_i)\n",
    "    error = prediction - target_i\n",
    "    cost_i = (error ** 2)\n",
    "    total_cost += cost_i\n",
    "    \n",
    "    # Display iteration information\n",
    "    print(f'Training Example {i + 1}:')\n",
    "    print(f'Theta values: {theta}')\n",
    "    print(f'Cost: {cost_i}')\n",
    "    print()\n",
    "\n",
    "# Calculate the average cost over the iterations\n",
    "average_cost = total_cost / len(data)\n",
    "print(f'Average Cost over the Iterations: {average_cost}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8e5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
